{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "29.1 YAPAY SİNİR AĞLARI [NEURAL NETWORKS]  \n",
    "\n",
    "1. Nöron : İnput (x bağımsız değişkenleri [ standartizason olmalı yani 0-1 arasında olmalı]) .... Nöron ......Output ( Y bağımlı değişkenler)\n",
    "2. Standartlaşma DL önemli tüm inputlar 0-1 arasında değer olmalı..\n",
    "3. Snapsis : İnputların ayrı ayrı bağlantıları ve üzerleirnde ağırlık (w1,w2,..) oluşuyor.\n",
    "4. Çoklu output çıktı oluşabilir.Sınıflandırma vb.\n",
    "5. Nöron giriş sinyali : x1w1+x2w2+....snapsislerden gelen farklı ağırlıktak bağımsız değişkenlerin toplamı,\n",
    "6. Nöron çıkış sinyali : Aktivasyon Fonksiyonları ile belirleniyor. Fonksiyonlar nöronun çıkış gücünü belirtiyor.\n",
    "7. 29.2 AKTİVASYON FONKSİYONLARI (BU FONK SONUCA ETKİSİ ÖNEMLİ)\n",
    "    a. Adım Fonksiyonu [Threshold Func] : \n",
    "        Nöron üzerine gelen yük bekliyor bekliyor ve thresholdu geçince 1 olup sinyal veriyor. YANİ YA 0 EŞİK DEĞERİ GEÇNCE 1 VAR\n",
    "    b. Sigmoik Func : 1 / 1 + e–¹ [KARAKTER ESLEM YAZ ARAYA] YANİ 0 EŞİK DEĞERİ GEÇİNCE S HARFİ GİBİ 0-1 ARASI VE BİYERDEN SONRA 1 VAR\n",
    "    C. RELU :  0 EŞİK DEĞERİNE KADAR 0 0 GEÇİNCE LİNEER GİRİŞ RAKAMI VER YANİ - DEĞERLERİ KESİYOR. \n",
    "    ..... birçok fonsiyon var.\n",
    "\n",
    "29.3 KATMANLAR LAYERS [ Giriş Katmanı - Gizli Katman - Çıkış Katmanı]\n",
    "                        Input Layer --- Hidden Layers ---Output Layer]\n",
    "     Katmanlarda farklı katman yada noronlar için ayrı aktivasyon fonk kullanılabilirler.\n",
    "29.5 YSA Nasıl Ögrenir. Perseptron [Train ve Test İşlemleri] Train işleminde Tahmini değer ile Gerçek Değer arasındaki fark azaltılmaya çalışılır.\n",
    "     Burada Geri Besleme yapılır. Geri Besleme Perseptron işleminde c = 1/2 ( Gerçek Deger - Tahmini Deger)²\n",
    "                                                                    c = 1/2 ( 1-0,1)2 = 0,405 geri besleme yapılacak ve mevcut W değerleri revize edilecek\n",
    ":LEARNING RATE [OGRENME DEGERİ] : C değerinin n kadar geri yansıyacağı ile ilgilidir.\n",
    "    \n",
    ":ORNEK:  \n",
    "----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Boy  Kilo Cinsiyet----- NORMALİZE EDİLMESİ [0-1 ARASINA ALINMASI]--\n",
    "NORMAL DEĞERLER         NORMALİZASYON STANDARTLASMA\n",
    "180  90    0             0.75    0.8   0\n",
    "150  50    1             0       0     1\n",
    "190  100   0             1       1     0\n",
    "165  55    1             0.375   0.1   1\n",
    "\n",
    "İŞLEM 1: \n",
    "-------------------------------------------------------- :    \n",
    "Boy\n",
    "0,75............ W1:1 .......\n",
    "                             TRESHOLD [1] A. cİNSİYET TAHMİNİ : 0,75*1 +0,80*1 = 1,55 > 1 true ateşleme yapıyor. Cinsiyet_Tahmini=1 ** Cinsiyet_Gerçek=0 = HATALI SEÇİM\n",
    "Kilo............ W2:1 .......             B. LEARNING RATE :-0.8 ALDIK [YANİ GERİ DONDURME KATSAYISI]\n",
    "0,80                                      C. HATALI SEÇİM OLDUĞU İÇİN PEANLTY CEZA VERİYOR. LR -0,8 OLDUĞU İÇİN AĞIRLIKLAR DÜŞÜYOR.\n",
    "                                          W1 : 1-0,8 = 0,2 OLUYOR VE W2 1-0,8 : 0,2 OLUYOR.\n",
    "Cinsiyet_GERCEK     : 0 \n",
    "Cinsiyet_TAHMİN     : 1   \n",
    "Tahmin tutmadı.Penalty değeri geri besleme : -0.8                  \n",
    "        \n",
    "İŞLEM 2:\n",
    "--------------------------------------------------------- :\n",
    "                        \n",
    "Boy\n",
    "0 .............. W1:0.2 .....\n",
    "                             TRESHOLD [1]   A. cİNSİYET TAHMİNİ : 0,2*0 +0,2*0 = 0 < 1 true ateşleme yapıyor. Cinsiyet_Tahmini=0 ** Cinsiyet_Gerçek=1 = HATALI SEÇİM\n",
    "Kilo............ W2:0.2..... [T Değişmeden] B. LEARNING RATE :-0.5 ALDIK [YANİ GERİ DONDURME KATSAYISI]\n",
    "0                                           C. HATALI SEÇİM OLDUĞU İÇİN PEANLTY CEZA VERİYOR. LR -0,5 OLDUĞU İÇİN AĞIRLIKLAR DÜŞÜYOR.\n",
    "                                               W1 : 1-0,8 = 0,2 OLUYOR VE W2 1-0,8 : 0,2 OLUYOR.\n",
    "Cinsiyet Gercek    : 1                    \n",
    "Cinsiyet Tahmini   : 0                   \n",
    "Tahmin tutmadı.Penalty değeri geri besleme : 0.5    \n",
    "\n",
    "İŞLEM 3:\n",
    "----------------------------------------------------------- :\n",
    "                        \n",
    "Boy\n",
    "1 ............ W1:0.7 .....\n",
    "                             TRESHOLD [1]   A. cİNSİYET TAHMİNİ : 0,7*1 +0,7*1 = 1,4 > 1 true ateşleme yapıyor. Cinsiyet_Tahmini=1 ** Cinsiyet_Gerçek=0 = HATALI SEÇİM\n",
    "Kilo\n",
    "1 ............ W2:0.7..... [T Değişmeden]   B. LEARNING RATE :-0.3 ALDIK [YANİ GERİ DONDURME KATSAYISI]\n",
    "                                            C. HATALI SEÇİM OLDUĞU İÇİN PEANLTY CEZA VERİYOR. LR -0,3 OLUYOR VE W2 0.7-0.3 : 0,4 OLUYOR.\n",
    "Cinsiyet Gercek    : 0                      \n",
    "Cinsiyet Tahmini   : 1                       \n",
    "Tahmin tutmadı.Penalty değeri azalarak geri besleme : -0.3                  \n",
    "\n",
    "                           \n",
    "İŞLEM 4:\n",
    "----------------------------------------------------------- :\n",
    "                        \n",
    "Boy\n",
    "0,375 ...........W1:0.4 .....\n",
    "                             TRESHOLD [1] A . cİNSİYET TAHMİNİ : 0,375*0,4 +0,4*0,1 > 1 true ateşleme yapıyor. Cinsiyet_Tahmini=1 ** Cinsiyet_Gerçek=1 = DOGRU TALI SEÇİM\n",
    "Kilo............ W2:0.4..... [T Değişmeden] B. LEARNING RATE : 0.0\n",
    "0,1                                         \n",
    "                                          \n",
    "Cinsiyet Gercek    : 1\n",
    "Cinsiyet Tahmini   : 1 Tahmin tuttu. Ögrenme [Training] Bitti.\n",
    "EN DOĞRU OPTIMIZE ÖGRENME NOKTASI BULUNDU. ]lEARNING RATE] *** BU COK ONEMLI\n",
    "\n",
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "TEST PHASE : Tekrar değerleri deneyerek bu ağırlıklar test edilir.                     \n",
    "                                             \n",
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "                       "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GERİ YAYILIM BACK PROPAGATION [ÇIKIŞTAN GİRİŞE]\n",
    "\n",
    "1. İLKLENDİRME YANİ LK DEGERLER AĞIRLIKLAR 0 OLMAYAN 0 YAKIN DEGERLER VERİLEREK BASLANIR.\n",
    "2. GİRİŞ KATMANINDA KAÇ NORON OLACAĞI = OZ NİTELİK SAYISI YANI X BAĞIMSIZ DEĞİŞKENİ KADARDIR. \n",
    "3. İLERİ YAYILIM YAPILARAK AĞIRLIKLAR GÜNCELLENİR. EPOCH\n",
    "4. GERÇEK VE ÇIKTI ARASINDAKİ FARK ERROR TESPİTİ YAPILIR.\n",
    "5. GERİ YAYILIM YAPILARAK ERROR GİDERİMİ İÇİN HER NORON (X) ÜZERİNDEKİ AĞIRLIK (W) HATADAN SORUMLU OLDUĞU KADAR VE LEARNING RATE İLE ORANTILI OLRAK DEĞİŞTİRİLİR. \n",
    "6. ADIM 1-5 ARASI İSTENEN SONUCA KADAR DEVAM EDER. GÜNCELLEME REINFORCED LEARNINIG İLE BASAMAK BASAMAK YADA BATCH YIGIN LEARNING İLE TEK SEFERDE YAPILIR. \n",
    "7. TUM EĞİTİM KUMESİ ÇALIŞTIRILDIĞINDA 1 EPOCH TAMAMLANMIŞ OLUR. AYNI KUMELRLE TEKRAR YAPILIR.KAÇ DEFA EPOCH YAPILACAK ONEML BU? DURMA NOKTASI BELİRLNMELİ.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MÜSTERİ KAYBININ ÖNLENMESİNE DAİR VERİ BİLİMİ DL PROJESİ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. KUTUPHANELERİN YUKLENMESİ [2.1-2.2]\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
      "0             1    15634602   Hargrave          619    France  Female   42   \n",
      "1             2    15647311       Hill          608     Spain  Female   41   \n",
      "2             3    15619304       Onio          502    France  Female   42   \n",
      "3             4    15701354       Boni          699    France  Female   39   \n",
      "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
      "...         ...         ...        ...          ...       ...     ...  ...   \n",
      "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
      "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
      "9997       9998    15584532        Liu          709    France  Female   36   \n",
      "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
      "9999      10000    15628319     Walker          792    France  Female   28   \n",
      "\n",
      "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0          2       0.00              1          1               1   \n",
      "1          1   83807.86              1          0               1   \n",
      "2          8  159660.80              3          1               0   \n",
      "3          1       0.00              2          0               0   \n",
      "4          2  125510.82              1          1               1   \n",
      "...      ...        ...            ...        ...             ...   \n",
      "9995       5       0.00              2          1               0   \n",
      "9996      10   57369.61              1          1               1   \n",
      "9997       7       0.00              1          0               1   \n",
      "9998       3   75075.31              2          1               0   \n",
      "9999       4  130142.79              1          1               0   \n",
      "\n",
      "      EstimatedSalary  Exited  \n",
      "0           101348.88       1  \n",
      "1           112542.58       0  \n",
      "2           113931.57       1  \n",
      "3            93826.63       0  \n",
      "4            79084.10       0  \n",
      "...               ...     ...  \n",
      "9995         96270.64       0  \n",
      "9996        101699.77       0  \n",
      "9997         42085.58       1  \n",
      "9998         92888.52       1  \n",
      "9999         38190.78       0  \n",
      "\n",
      "[10000 rows x 14 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[619, 'France', 'Female', ..., 1, 1, 101348.88],\n",
       "        [608, 'Spain', 'Female', ..., 0, 1, 112542.58],\n",
       "        [502, 'France', 'Female', ..., 1, 0, 113931.57],\n",
       "        ...,\n",
       "        [709, 'France', 'Female', ..., 0, 1, 42085.58],\n",
       "        [772, 'Germany', 'Male', ..., 1, 0, 92888.52],\n",
       "        [792, 'France', 'Female', ..., 1, 0, 38190.78]], dtype=object),\n",
       " array([1, 0, 1, ..., 1, 1, 0], dtype=int64),\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2. VERİNİN (.CSV) İÇE YÜKLEMESİ ve PD DATAFRAME OLUŞTURMA (comma seperated value virgulle ayrılan veriler ) [2.3]-[2.4]\n",
    "\n",
    "veriler = pd.read_csv(\"model.csv\")\n",
    "# MUSTERİ KAYIP ANALİZİ [KAYBEDECEĞİMİZİ NASIL ANLARIZ]\n",
    "# YENİ MUSTERİ KAZANMAK ELDEKİ MUSTERİYİ KAYETMEMEKTEN 3 KAT DAHA PAHALI BUNDAN DOLAYI BU ANALİZ ÖNEMLİ\n",
    "print(veriler)\n",
    "veriler.info()\n",
    "'''\n",
    "[10000 rows x 14 columns]\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "PANDAS DATAFRAME OLDUĞU YAZILI YUKARIDA SATIR İNDEX NU VAR.\n",
    "\n",
    "RangeIndex: 10000 entries, 0 to 9999\n",
    "Data columns (total 14 columns):\n",
    " #   Column           Non-Null Count  Dtype  \n",
    "---  ------           --------------  -----  \n",
    " 0   RowNumber        10000 non-null  int64    ÖĞRENME İÇİN GEREKSİZ BAĞIMSIZ DEĞİŞKEN OVERFITTING YAPAR\n",
    " 1   CustomerId       10000 non-null  int64    ÖĞRENME İÇİN GEREKSİZ BAĞIMSIZ DEĞİŞKEN OVERFITTING YAPAR\n",
    " 2   Surname          10000 non-null  object   ÖĞRENME İÇİN GEREKSİZ BAĞIMSIZ DEĞİŞKEN OVERFITTING YAPAR\n",
    "YUKARDAKİ DEĞİŞKENLER BAĞIMSIZ DEĞİŞKEN SIFATI TAŞIMIYOR.****************************************************** \n",
    "\n",
    " 3   CreditScore      10000 non-null  int64    DL(0-1) ARASINDA DEĞİL OHE YAPILMALI VE SAYISAL VERİ OLMALI\n",
    " 4   Geography        10000 non-null  object   KATOGORİK VERİLERİN DL İÇİN[0-1] ARASINA ENCODING YAPILMASI LAZIM\n",
    " 5   Gender           10000 non-null  object   KATOGORİK VERİLERİN DL İÇİN[0-1] ARASINA ENCODING YAPILMASI LAZIM\n",
    " 7   Tenure           10000 non-null  int64    DL(0-1) ARASINDA DEĞİL OHE YAPILMALI VE SAYISAL VERİ OLMALI\n",
    " 8   Balance          10000 non-null  float64  DL(0-1) ARASINDA DEĞİL OHE YAPILMALI VE SAYISAL VERİ OLMALI\n",
    " 9   NumOfProducts    10000 non-null  int64    DL(0-1) ARASINDA DEĞİL OHE YAPILMALI VE SAYISAL VERİ OLMALI\n",
    " 10  HasCrCard        10000 non-null  int64  \n",
    " 11  IsActiveMember   10000 non-null  int64  \n",
    " 12  EstimatedSalary  10000 non-null  float64\n",
    " YUKARIDAKİ DEĞİŞKENLER BAĞIMSIZ X DEĞİŞKEN SIFATI TAŞIYOR.*****************************************************\n",
    " \n",
    " 13  Exited           10000 non-null  int64    BAĞIMLI (Y) DEĞİŞKENİ MÜŞTERİ BİZİ BIRAKTI MI BIRAKMADI MI? BUNU TAHMİN EDECEK \n",
    " YUKARIDAKİ DEĞİŞKEN BAĞIMLI Y DEĞİŞKENİ YANİ SONUÇTA DEĞERLENDİRİLİECEK DEĞİŞKEN 0: BİZİ BIRAKMIYCAK ***************\n",
    " \n",
    " MODEL YAPICAZ.. \n",
    " **************************************************************************************************************\n",
    "dtypes: float64(2), int64(9), object(3)        (0) BIRAKMAYANLAR + (1) BIRAKANLAR\n",
    "'''\n",
    "# 2a. ON İŞLEME \n",
    "  # 2a1. Pandas Dataframe içindeki sutunları X (BAGIMSIZ) VE Y(BAĞIMLI) DEĞİŞKEN DİZİLERİ OLARAK AYIRMA\n",
    "     # İlk 3 değişken gereksiz bu yüzden bağımsız x değişkenlerinden ayrılacak.\n",
    "      # Excited 0 Bırakmayanlar Y Bağımlı Değişkeni \n",
    "  \n",
    "\n",
    "X = veriler.iloc[:,3:13].values # X Bağımsız değişkenleri (tum satırlar,İNDEX 3 dahil:İndex 13 hariç tum sutunlar) alındı.Pandas Dataframeden .values ile numpy array yapıldı\n",
    "Y = veriler.iloc[:,13].values # Y Bağımlı değişkeni alındı.Pandas Dataframeden .values ile numpy array yapıldı\n",
    "\n",
    "X,Y,type(Y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "**************************************************************************************************************************\n",
    "# 2b. Obje Oriented Moddeling [2.4]\n",
    "\n",
    "class sevik:\n",
    "# sevik isminde sınıf tanımlandı ve aşağdakı method yada fonklar tanımlandı.\n",
    "    surname = \"Sevik\"\n",
    "    memleket = \"Manisa\"\n",
    "    yıl = 2022\n",
    "\n",
    "# egitim isminde method tanımlandı.methodların parametresi() olur ve \"self parametresini\" unutma .....\n",
    "    def egitim (self,k):\n",
    "        return 2021-k\n",
    "    \n",
    "# yas isminde method tanımlandı.\"self parametresini\" unutma .....\n",
    "    def yas(self,d_tar):\n",
    "        return 2021-d_tar\n",
    "    \n",
    "# sevik sınıfından atakan objesi tanımlandı.  \n",
    "atakan = sevik()\n",
    "\n",
    "#atakan objesi attributlerını print edelim.\n",
    "print(\"Soyadı :\" ,atakan.surname)\n",
    "print(\"Memleketi :\", atakan.memleket)\n",
    "print(\"Eğitim Yılı: \",atakan.egitim(2011), \"yıl\")\n",
    "print(\"Eğitim Süresi: \",atakan.yas(2005),\"yıl\")\n",
    "****************************************************************************************************************************\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 2c. ON İŞLEME - Eksik Verilerle Çalışma [2.5] EKSİK VERİ BU ORNEKTE YOK\n",
    "\n",
    "'''\n",
    "# Ortalama ile imputer yapalım.\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "Yas = veriler.iloc[:,1:4].values\n",
    "print(Yas)\n",
    "# Ortalama ile sayısal kolonlardaki eksik değerleri FIT ile tespit edilen ortalama degerler ile TRANSFORM imputer yapalım.\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "# eksik veriler ortalama stratejisi ile imputer objesine atandı SimpleImputer tarafından\n",
    "imputer = imputer.fit(Yas[:,1:4])\n",
    "# 1 ve 4 ncü sutunlar arasındaki tüm sutunlarIN MEVCUT DEĞERLERİNDEN tespit edilen ortalama ile FIT TRAIN edilerek değerler imputer objesine atandı. (28.45 deger oldu)\n",
    "Yas[:,1:4] = imputer.transform(Yas[:,1:4])\n",
    "# TRAIN edilen değerler sonucu tespit edilen değer TRANSFORM ile Nan değerleri değiştirecek\n",
    "print(Yas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 619, ..., 1, 1, 101348.88],\n",
       "       [0.0, 1.0, 608, ..., 0, 1, 112542.58],\n",
       "       [0.0, 0.0, 502, ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [0.0, 0.0, 709, ..., 0, 1, 42085.58],\n",
       "       [1.0, 0.0, 772, ..., 1, 0, 92888.52],\n",
       "       [0.0, 0.0, 792, ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2d. ON İŞLEME - ENCODING (LE-OHE-CT) Katogorik Verilerle Çalışma [2.6] GEOGRAPHY AND GENDER katogorik verileri\n",
    " # [CT:Column Transformer öğereneceğiz burada]\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 2d1. KATOGORİK VERİ ENCODING -- [LABEL ENCODING] ---------------------------------------------------------------------\n",
    "       # geo katogorik verilerin LE ile encode edilmesi\n",
    "le = preprocessing.LabelEncoder()\n",
    "X[:,1] = le.fit_transform(X[:,1])\n",
    "       # İlk 3 sutunu temizlenen ve O DEĞİL 1 nci INDEX KOLUNU Kat Geo VERİLERİ FİT edilip LAbel Encodingle SAYISAL VERİYE çevrildi. \n",
    "    \n",
    "       # gender katogorik verilerin LE ile encode edilmesi (le2 yaptık cunku yukarıdki le geo ile train edildi.)\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "X[:,2] = le2.fit_transform(X[:,2])\n",
    "       # İlk 3 sutunu temizlenen ve 2 nci INDEX KOLONU Gender VERİLERİ FİT edilip LE ile sayısala cevrildi.\n",
    "\n",
    "# 2d2. KATOGORİK VERİ ENCODING -- COLUMN TRANSFORMER VE ONE HOT ENCODER İLE FARKLI KATOGORİKLERİN DÖNÜŞTÜRÜLMESİ--------\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "ohe = ColumnTransformer([(\"ohe\", OneHotEncoder(dtype=float),[1])], remainder='passthrough')\n",
    "X = ohe.fit_transform(X)\n",
    "X = X[:,1:]\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 477 ... 0 0 163112.9]\n",
      " [0.0 0.0 794 ... 1 1 74275.08]\n",
      " [0.0 0.0 570 ... 0 1 62810.91]\n",
      " ...\n",
      " [0.0 0.0 738 ... 1 0 181429.87]\n",
      " [0.0 1.0 590 ... 1 1 148750.16]\n",
      " [1.0 0.0 623 ... 1 0 118855.26]]\n",
      "[1 0 0 ... 0 0 1]\n",
      "[[1.0 0.0 597 ... 1 1 192852.67]\n",
      " [0.0 0.0 523 ... 1 0 128702.1]\n",
      " [0.0 1.0 706 ... 1 1 75732.25]\n",
      " ...\n",
      " [0.0 1.0 684 ... 0 0 120284.67]\n",
      " [1.0 0.0 577 ... 0 0 125140.72]\n",
      " [0.0 0.0 736 ... 0 1 192131.77]]\n",
      "[0 1 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# 3. VERİLERİN TEST VE TRAIN OLARAK BÖLÜNMESİ [2.8]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.33,random_state=0)\n",
    "\n",
    "print(x_train)\n",
    "print(y_train)\n",
    "print(x_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.56953701, -0.57436296, -1.78451879, ..., -1.56299709,\n",
       "        -1.03339307,  1.0890591 ],\n",
       "       [-0.56953701, -0.57436296,  1.47401668, ...,  0.63979645,\n",
       "         0.967686  , -0.4551902 ],\n",
       "       [-0.56953701, -0.57436296, -0.82854466, ..., -1.56299709,\n",
       "         0.967686  , -0.65446947],\n",
       "       ...,\n",
       "       [-0.56953701, -0.57436296,  0.89837634, ...,  0.63979645,\n",
       "        -1.03339307,  1.40745917],\n",
       "       [-0.56953701,  1.74105933, -0.62295883, ...,  0.63979645,\n",
       "         0.967686  ,  0.83939459],\n",
       "       [ 1.75581215, -0.57436296, -0.2837422 , ...,  0.63979645,\n",
       "        -1.03339307,  0.31973777]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. VERİLERİN ÖZNİTELİK ÖLÇEKLENMESİ [2.9] ANN-DEEP LEARNING İÇİN DEĞERLER 0-1 ARASI OLACAK\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(x_train)\n",
    "X_test = sc.fit_transform(x_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 11. KERAS İLE YAPAT SINIR AĞI İŞLEMLERİ:\n",
    "      # Keras'ın temel veri yapıları katmanlar ve modellerdir.\n",
    "      # En basit model türü, doğrusal bir katman yığını olan Sıralı [SEQUENTIAL MAODEL] modeldir.\n",
    "      # Daha karmaşık mimariler için, isteğe bağlı katman grafikleri oluşturmaya veya alt sınıflar aracılığıyla tamamen\n",
    "      # sıfırdan modeller yazmaya izin veren Keras işlevsel API'sini kullanmalısınız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 11a.MODEL OLUŞTURMA: Sequential Model keras tf üzerinden kuruldu ve model objesi yaratıldı.\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "model = Sequential() \n",
    "\n",
    "# Bir yapay sinir ağı model obje olarak temel Seq modelden boş oluşturuldu altta içini dolduracağız.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 11b. KATMAN /LAYER(DENSE) OLUŞTURMA: Layers/Katmanlar .add() ile oluşturuldu:Her Noron Katmanı Dense ile oluşturuldu\n",
    "\n",
    "'''\n",
    "tf.keras.layers.Dense(\n",
    "    units, [ kaç tane katmanda noron olacak ]\n",
    "    activation=None, [ Akt Fonk ne olacak]\n",
    "    use_bias=True, [ Düzeltme Yapılacak mı]\n",
    "    kernel_initializer=\"glorot_uniform\",\n",
    "    bias_initializer=\"zeros\",\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    **kwargs\n",
    ")\n",
    "'''\n",
    "# On işleme neticesinde 11 adet Bagımsız Değişken (x) oluşturduk. Çıkış sadece 1 adet (y) excited kolunu oluşturduk.\n",
    "# İpucu [ÜCGEN YAPI]: Bundan dolayı giriş için 11 units,çıkış için 1 units topla ve böl ikiye 6 ile oluşturmak işe yarıyor.\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "model.add(Dense(units=6,kernel_initializer=\"glorot_uniform\", activation='relu',input_dim=11))\n",
    "# 1 NCİ GİZLİ KATMAN [GİRİŞ KATMANI - Input_dimension X Bağımsız dğişken sayısı BELİRTİLEN]\n",
    "model.add(Dense(units=6,kernel_initializer=\"glorot_uniform\", activation='relu'))  \n",
    "# 2 NCİ GİZLİ KATMAN \n",
    "model.add(Dense(units=1,kernel_initializer=\"glorot_uniform\",activation='sigmoid'))          \n",
    "# ÇIKIŞ KATMANI 1 Noron var (o: Bırakır, 1: Bırakmaz verecek)+ cıkışlar genelde sigmoid fonk olur.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\\n              loss=tf.keras.losses.BinaryCrossentropy(),\\n              metrics=[tf.keras.metrics.BinaryAccuracy(),\\n                       tf.keras.metrics.FalseNegatives()])\\n\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11c. COMPILE / DERLEME ETMEK :\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "'''\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
    "                       tf.keras.metrics.FalseNegatives()])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.5392 - accuracy: 0.7919\n",
      "Epoch 2/50\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7987\n",
      "Epoch 3/50\n",
      "210/210 [==============================] - 0s 997us/step - loss: 0.4409 - accuracy: 0.8033\n",
      "Epoch 4/50\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.4301 - accuracy: 0.8103\n",
      "Epoch 5/50\n",
      "210/210 [==============================] - 0s 926us/step - loss: 0.4232 - accuracy: 0.8139\n",
      "Epoch 6/50\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.4177 - accuracy: 0.8197\n",
      "Epoch 7/50\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.4130 - accuracy: 0.8240\n",
      "Epoch 8/50\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.4087 - accuracy: 0.8264\n",
      "Epoch 9/50\n",
      "210/210 [==============================] - 0s 983us/step - loss: 0.4047 - accuracy: 0.8287\n",
      "Epoch 10/50\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.4010 - accuracy: 0.8294\n",
      "Epoch 11/50\n",
      "210/210 [==============================] - 0s 944us/step - loss: 0.3975 - accuracy: 0.8300\n",
      "Epoch 12/50\n",
      "210/210 [==============================] - 0s 947us/step - loss: 0.3942 - accuracy: 0.8333\n",
      "Epoch 13/50\n",
      "210/210 [==============================] - 0s 957us/step - loss: 0.3908 - accuracy: 0.8360\n",
      "Epoch 14/50\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.3879 - accuracy: 0.8345\n",
      "Epoch 15/50\n",
      "210/210 [==============================] - 0s 932us/step - loss: 0.3858 - accuracy: 0.8375\n",
      "Epoch 16/50\n",
      "210/210 [==============================] - 0s 937us/step - loss: 0.3837 - accuracy: 0.8366\n",
      "Epoch 17/50\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.3815 - accuracy: 0.8381\n",
      "Epoch 18/50\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.3798 - accuracy: 0.8372\n",
      "Epoch 19/50\n",
      "210/210 [==============================] - 0s 935us/step - loss: 0.3784 - accuracy: 0.8375\n",
      "Epoch 20/50\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.3770 - accuracy: 0.8369\n",
      "Epoch 21/50\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.3751 - accuracy: 0.8378\n",
      "Epoch 22/50\n",
      "210/210 [==============================] - 0s 934us/step - loss: 0.3738 - accuracy: 0.8385\n",
      "Epoch 23/50\n",
      "210/210 [==============================] - 0s 938us/step - loss: 0.3725 - accuracy: 0.8376\n",
      "Epoch 24/50\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.3714 - accuracy: 0.8375\n",
      "Epoch 25/50\n",
      "210/210 [==============================] - 0s 932us/step - loss: 0.3699 - accuracy: 0.8387\n",
      "Epoch 26/50\n",
      "210/210 [==============================] - 0s 937us/step - loss: 0.3690 - accuracy: 0.8413\n",
      "Epoch 27/50\n",
      "210/210 [==============================] - 0s 910us/step - loss: 0.3681 - accuracy: 0.8431\n",
      "Epoch 28/50\n",
      "210/210 [==============================] - 0s 914us/step - loss: 0.3671 - accuracy: 0.8455\n",
      "Epoch 29/50\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.3665 - accuracy: 0.8457\n",
      "Epoch 30/50\n",
      "210/210 [==============================] - 0s 946us/step - loss: 0.3655 - accuracy: 0.8454\n",
      "Epoch 31/50\n",
      "210/210 [==============================] - 0s 932us/step - loss: 0.3646 - accuracy: 0.8448\n",
      "Epoch 32/50\n",
      "210/210 [==============================] - 0s 991us/step - loss: 0.3639 - accuracy: 0.8476\n",
      "Epoch 33/50\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.3631 - accuracy: 0.8485\n",
      "Epoch 34/50\n",
      "210/210 [==============================] - 0s 950us/step - loss: 0.3623 - accuracy: 0.8485\n",
      "Epoch 35/50\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.3614 - accuracy: 0.8499\n",
      "Epoch 36/50\n",
      "210/210 [==============================] - 0s 921us/step - loss: 0.3608 - accuracy: 0.8497\n",
      "Epoch 37/50\n",
      "210/210 [==============================] - 0s 929us/step - loss: 0.3603 - accuracy: 0.8510\n",
      "Epoch 38/50\n",
      "210/210 [==============================] - 0s 990us/step - loss: 0.3596 - accuracy: 0.8518\n",
      "Epoch 39/50\n",
      "210/210 [==============================] - 0s 956us/step - loss: 0.3590 - accuracy: 0.8534\n",
      "Epoch 40/50\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.3583 - accuracy: 0.8518\n",
      "Epoch 41/50\n",
      "210/210 [==============================] - 0s 975us/step - loss: 0.3577 - accuracy: 0.8522\n",
      "Epoch 42/50\n",
      "210/210 [==============================] - 0s 950us/step - loss: 0.3571 - accuracy: 0.8530\n",
      "Epoch 43/50\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.3567 - accuracy: 0.8540\n",
      "Epoch 44/50\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.3561 - accuracy: 0.8536\n",
      "Epoch 45/50\n",
      "210/210 [==============================] - 0s 944us/step - loss: 0.3547 - accuracy: 0.8558\n",
      "Epoch 46/50\n",
      "210/210 [==============================] - 0s 929us/step - loss: 0.3543 - accuracy: 0.8564\n",
      "Epoch 47/50\n",
      "210/210 [==============================] - 0s 937us/step - loss: 0.3537 - accuracy: 0.8554\n",
      "Epoch 48/50\n",
      "210/210 [==============================] - 0s 950us/step - loss: 0.3533 - accuracy: 0.8573\n",
      "Epoch 49/50\n",
      "210/210 [==============================] - 0s 931us/step - loss: 0.3523 - accuracy: 0.8569\n",
      "Epoch 50/50\n",
      "210/210 [==============================] - 0s 929us/step - loss: 0.3517 - accuracy: 0.8575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nModel.fit( x=None,y=None,\\n            batch_size=None,\\n            epochs=1,\\n            verbose=\"auto\",\\n            callbacks=None,\\n            validation_split=0.0,\\n            validation_data=None,\\n            shuffle=True,\\n            class_weight=None,\\n            sample_weight=None,\\n            initial_epoch=0,\\n            steps_per_epoch=None,\\n            validation_steps=None,\\n            validation_batch_size=None,\\n            validation_freq=1,\\n            max_queue_size=10,\\n            workers=1,\\n            use_multiprocessing=False,)\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11.d. TRAIN VE FIT ETMEK :\n",
    "\n",
    "model.fit( X_train , y_train , epochs=50) \n",
    "\n",
    "# scale edilmiş X bağımsız değişkenlerinden zaten(0-1 arası olan) bağımlı y değişkeni öğrenecek,\n",
    "# 50 tur da öğrenecek\n",
    "\n",
    "\n",
    "'''\n",
    "Model.fit( x=None,y=None,\n",
    "            batch_size=None,\n",
    "            epochs=1,\n",
    "            verbose=\"auto\",\n",
    "            callbacks=None,\n",
    "            validation_split=0.0,\n",
    "            validation_data=None,\n",
    "            shuffle=True,\n",
    "            class_weight=None,\n",
    "            sample_weight=None,\n",
    "            initial_epoch=0,\n",
    "            steps_per_epoch=None,\n",
    "            validation_steps=None,\n",
    "            validation_batch_size=None,\n",
    "            validation_freq=1,\n",
    "            max_queue_size=10,\n",
    "            workers=1,\n",
    "            use_multiprocessing=False,)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11.e PREDICT TAHMİN ETMEK :\n",
    "'''\n",
    "Model.predict(\n",
    "    x,\n",
    "    batch_size=None,\n",
    "    verbose=0,\n",
    "    steps=None,\n",
    "    callbacks=None,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False,\n",
    ")\n",
    "'''\n",
    "y_pred = model.predict(X_test) \n",
    "# 33% scale yani normailze edilen (X/0-1 arasına alınan) X bağımsız test verileri ile scale edilmemiş y verilerini tahmin edecek.\n",
    "# BAKALIM GERÇEK VERİLERLE NE KADAR YAKIN OLACAK.\n",
    "y_pred = (y_pred > 0.5)\n",
    "# sacle edildiği için 0.5 altını 0 ve üstünü 1 kabul edecek,boolean döndürcek False/True\n",
    "# yeni y_pred =1 (Müşteri bırakır olarak belirledik)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2490,  127],\n",
       "       [ 368,  315]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12. KARŞILAŞTIRMA MATRIXI\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "# Memnuniyet y test gercek değerleri ile tahmin değerlerini Matrixde [Accuracy] karşilastıracağız.\n",
    "cm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Gercek : 0 ve Tahmin:0 = 2490\n",
    "Gercek : 0 ve Tahmin:1 = 368\n",
    "Gercek : 1 ve Tahmin:0 = 127\n",
    "Gercek : 1 ve Tahmin:1 = 315 YANİ 315+2490= 2805 (85%) DOGRU, 368+127=495 (15%) YANLIŞ TAHMİN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
