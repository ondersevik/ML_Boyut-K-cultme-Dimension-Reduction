{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "#                     BOYUT Ä°NDÄ°RGEME                   :\n",
    "------------------------------------------------------------------------\n",
    "1. BOYUT DÃ–NÃœÅžTÃœRME GEREKSÄ°Z BOYUTLARDAN KURTULMA VEYA BAZILARINI BÄ°RLEÅžTÄ°RME \n",
    "2. DEÄžÄ°ÅžKENLER ARASINDAKÄ° BAÄžLANTI (KORELASYONLARI ORTAYA Ã‡IKARMA)\n",
    "3. EIGEN VALUE : Ã–Z DEÄžER (SKALAR),\n",
    "4. EIGEN VECTOR : Ã–Z YÃ–NEY (VEKTÃ–R)\n",
    "        \n",
    "+1 2 +0      1       3 (1*1 +2*1+0*1)           1\n",
    "+0 1 +2   *  1   =   3                  =    3  1\n",
    "-1 0 -2      0       0                          0\n",
    "\n",
    "\n",
    "BURADA ;\n",
    "\n",
    "Ã‡ARPAN +3 Ã–Z DEÄžER,\n",
    "VEKTOR [1,1,0] Ã–Z YÃ–NEY\n",
    "\n",
    "1. PCA (PRINCIPAL COMPANANT ANALYSIS- BÄ°RÄ°NCÄ°L BÄ°LEÅžEN ANALÄ°ZÄ°) ALGORÄ°TMASI    :\n",
    "-----------------------------------------------------------------------------\n",
    "UNSUPERVISED GÃ–ZETÄ°MSÄ°Z YAPIDADIR. CLUSTERING VARDIR. SINIF ETÄ°KETLERÄ° IGNORE EDÄ°LÄ°YOR.\n",
    "\n",
    "1. Ä°NDÄ°RGENECEK BOYUT : K OLSUN\n",
    "2. VERÄ° STANDARTLAÅžTIRMASI YAP\n",
    "3. KOVARYANS VE KORELASYON MATRÄ°SÄ°NDEN Ã–Z DEÄžER VE Ã–Z YÃ–NEY ELDE ET.\n",
    "4. Ã–Z DEÄžERLERÄ° AZALARAK SIRALA VE K TANESÄ°NÄ° AL.\n",
    "5. K Ã–ZDEÄžERDEN W PROJESÄ° MATRIX OLUÅžTUR.\n",
    "6. ORJÄ°NAL VERÄ° KUMESÄ° [X] ; W KULLANARAK DÃ–ÃœÅžTÃœR VE K-BOYUT UZAY ELDE ET.\n",
    "\n",
    "2. LDA (LINEAR DISCRIMINANT ANALYSÄ°S- DOÄžRUSAL AYRIÅžMA ANALÄ°ZÄ°) ALGORÄ°TMASI    :\n",
    "-----------------------------------------------------------------------------\n",
    "SUPERVISED GÃ–ZETÄ°MLÄ° YAPIDADIR. ETÄ°KETLÄ° VERÄ°LER OLUR. VERÄ°LERÄ°N SINIFLARINI AYRIÅžTIRIR.\n",
    "sebastianraschka.com sayfasÄ±nda detaylÄ± LDA makalesi mevcuttur.\n",
    "\n",
    "VERÄ° SINIFLARININ AYRIÅžTIRILMASI HARÄ°Ã‡ PCA Ä°LE AYNIDIR. \n",
    "\n",
    "NEREDE KULLANILACAK                                                          :\n",
    "------------------------------------------------------------------------------\n",
    "1. GÃœRÃœLTÃœ FÄ°LTERELEME : ANOMALÄ°YE KAÅžI DERENÃ‡ OLUÅžTURUR.\n",
    "2. GÃ–RSELLEÅžTÄ°RME\n",
    "3. Ã–Z NÄ°TELÄ°K Ã‡IKARIMI : FEATURE EXTRACTION\n",
    "4. Ã–Z NÄ°TELÄ°K NÄ°TELÄ°K ELEME YADA DÃ–NÃœÅžTÃœRME : GEREKSÄ°Z FEATURE VARSA ELEME YAPILIR.\n",
    "5. BORSA ANALÄ°ZÄ°\n",
    "6. SAÄžLIK VE GENETÄ°K VERÄ°LER \n",
    "7. YER BÄ°LÄ°MÄ° GEO SCIENCE VB...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. KUTUPHANELERÄ°N YUKLENMESÄ° [2.1-2.2]\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Alcohol  Malic_Acid   Ash  Ash_Alcanity  Magnesium  Total_Phenols  \\\n",
      "0      14.23        1.71  2.43          15.6        127           2.80   \n",
      "1      13.20        1.78  2.14          11.2        100           2.65   \n",
      "2      13.16        2.36  2.67          18.6        101           2.80   \n",
      "3      14.37        1.95  2.50          16.8        113           3.85   \n",
      "4      13.24        2.59  2.87          21.0        118           2.80   \n",
      "..       ...         ...   ...           ...        ...            ...   \n",
      "173    13.71        5.65  2.45          20.5         95           1.68   \n",
      "174    13.40        3.91  2.48          23.0        102           1.80   \n",
      "175    13.27        4.28  2.26          20.0        120           1.59   \n",
      "176    13.17        2.59  2.37          20.0        120           1.65   \n",
      "177    14.13        4.10  2.74          24.5         96           2.05   \n",
      "\n",
      "     Flavanoids  Nonflavanoid_Phenols  Proanthocyanins  Color_Intensity   Hue  \\\n",
      "0          3.06                  0.28             2.29             5.64  1.04   \n",
      "1          2.76                  0.26             1.28             4.38  1.05   \n",
      "2          3.24                  0.30             2.81             5.68  1.03   \n",
      "3          3.49                  0.24             2.18             7.80  0.86   \n",
      "4          2.69                  0.39             1.82             4.32  1.04   \n",
      "..          ...                   ...              ...              ...   ...   \n",
      "173        0.61                  0.52             1.06             7.70  0.64   \n",
      "174        0.75                  0.43             1.41             7.30  0.70   \n",
      "175        0.69                  0.43             1.35            10.20  0.59   \n",
      "176        0.68                  0.53             1.46             9.30  0.60   \n",
      "177        0.76                  0.56             1.35             9.20  0.61   \n",
      "\n",
      "     OD280  Proline  Customer_Segment  \n",
      "0     3.92     1065                 1  \n",
      "1     3.40     1050                 1  \n",
      "2     3.17     1185                 1  \n",
      "3     3.45     1480                 1  \n",
      "4     2.93      735                 1  \n",
      "..     ...      ...               ...  \n",
      "173   1.74      740                 3  \n",
      "174   1.56      750                 3  \n",
      "175   1.56      835                 3  \n",
      "176   1.62      840                 3  \n",
      "177   1.60      560                 3  \n",
      "\n",
      "[178 rows x 14 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Alcohol               178 non-null    float64\n",
      " 1   Malic_Acid            178 non-null    float64\n",
      " 2   Ash                   178 non-null    float64\n",
      " 3   Ash_Alcanity          178 non-null    float64\n",
      " 4   Magnesium             178 non-null    int64  \n",
      " 5   Total_Phenols         178 non-null    float64\n",
      " 6   Flavanoids            178 non-null    float64\n",
      " 7   Nonflavanoid_Phenols  178 non-null    float64\n",
      " 8   Proanthocyanins       178 non-null    float64\n",
      " 9   Color_Intensity       178 non-null    float64\n",
      " 10  Hue                   178 non-null    float64\n",
      " 11  OD280                 178 non-null    float64\n",
      " 12  Proline               178 non-null    int64  \n",
      " 13  Customer_Segment      178 non-null    int64  \n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 19.6 KB\n",
      "[[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
      " ...\n",
      " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
      " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
      " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "## 2. VERÄ°NÄ°N (.CSV) Ä°Ã‡E YÃœKLEMESÄ° ve PD DATAFRAME OLUÅžTURMA (comma seperated value virgulle ayrÄ±lan veriler ) [2.3]-[2.4]\n",
    "\n",
    "veriler = pd.read_csv(\"20220225_PCA Boyut Ä°ndirgeme Analizi_PSA_Wine.csv\")\n",
    "# MUSTERÄ° KAYIP ANALÄ°ZÄ° [KAYBEDECEÄžÄ°MÄ°ZÄ° NASIL ANLARIZ]\n",
    "# YENÄ° MUSTERÄ° KAZANMAK ELDEKÄ° MUSTERÄ°YÄ° KAYETMEMEKTEN 3 KAT DAHA PAHALI BUNDAN DOLAYI BU ANALÄ°Z Ã–NEMLÄ°\n",
    "print(veriler)\n",
    "veriler.info()\n",
    "'''\n",
    "178 rows x 14 columns]\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 178 entries, 0 to 177\n",
    "Data columns (total 14 columns):\n",
    " #   Column                Non-Null Count  Dtype  \n",
    "---  ------                --------------  -----  \n",
    " 0   Alcohol               178 non-null    float64 : BaÄŸÄ±msÄ±z DeÄŸiÅŸken\n",
    " 1   Malic_Acid            178 non-null    float64 : BaÄŸÄ±msÄ±z DeÄŸiÅŸken\n",
    " 2   Ash                   178 non-null    float64 : BaÄŸÄ±msÄ±z DeÄŸiÅŸken\n",
    " 3   Ash_Alcanity          178 non-null    float64 : BaÄŸÄ±msÄ±z DeÄŸiÅŸken\n",
    " 4   Magnesium             178 non-null    int64   : BaÄŸÄ±msÄ±z DeÄŸiÅŸken\n",
    " 5   Total_Phenols         178 non-null    float64 : BaÄŸÄ±msÄ±z DeÄŸiÅŸken\n",
    " 6   Flavanoids            178 non-null    float64 : BaÄŸÄ±msÄ±z DeÄŸiÅŸken\n",
    " 7   Nonflavanoid_Phenols  178 non-null    float64 : BaÄŸÄ±msÄ±z DeÄŸiÅŸken\n",
    " 8   Proanthocyanins       178 non-null    float64 : BaÄŸÄ±msÄ±z DeÄŸiÅŸken\n",
    " 9   Color_Intensity       178 non-null    float64 : BaÄŸÄ±msÄ±z DeÄŸiÅŸken\n",
    " 10  Hue                   178 non-null    float64 : BaÄŸÄ±msÄ±z DeÄŸiÅŸken\n",
    " 11  OD280                 178 non-null    float64 : BaÄŸÄ±msÄ±z DeÄŸiÅŸken\n",
    " 12  Proline               178 non-null    int64   : BaÄŸÄ±msÄ±z DeÄŸiÅŸken\n",
    " 13  Customer_Segment      178 non-null    int64   : BAÄžIMLI DEÄžÄ°ÅžKEN Y\n",
    "\n",
    "dtypes: float64(11), int64(3)\n",
    "memory usage: 19.6 KB\n",
    "\n",
    "'''\n",
    "# 2a. ON Ä°ÅžLEME \n",
    "  # 2a1. Pandas Dataframe iÃ§indeki sutunlarÄ± X (BAGIMSIZ) VE Y(BAÄžIMLI) DEÄžÄ°ÅžKEN DÄ°ZÄ°LERÄ° OLARAK AYIRMA\n",
    "     # Ä°lk 3 deÄŸiÅŸken gereksiz bu yÃ¼zden baÄŸÄ±msÄ±z x deÄŸiÅŸkenlerinden ayrÄ±lacak.\n",
    "      # Excited 0 BÄ±rakmayanlar Y BaÄŸÄ±mlÄ± DeÄŸiÅŸkeni \n",
    "  \n",
    "X = veriler.iloc[:,0:13].values \n",
    "# [ tÃ¼m satÄ±rlar, 0-13 arasÄ±ndaki tÃ¼m sÃ¼tÃ¼nlar] iloc ile X BaÄŸÄ±msÄ±z deÄŸiÅŸkenleri alÄ±ndÄ±.\n",
    "# Pandas Dataframeden .values ile numpy array yapÄ±ldÄ±\n",
    "Y = veriler.iloc[:,13].values \n",
    "# [ tÃ¼m satÄ±rlar, 13 ncÃ¼ sutun ] Y BaÄŸÄ±mlÄ± deÄŸiÅŸkeni customer segment alÄ±ndÄ±.\n",
    "# Pandas Dataframeden .values ile numpy array yapÄ±ldÄ±\n",
    "\n",
    "print (X),\n",
    "print (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.369e+01 3.260e+00 2.540e+00 ... 9.600e-01 1.820e+00 6.800e+02]\n",
      " [1.269e+01 1.530e+00 2.260e+00 ... 9.600e-01 2.060e+00 4.950e+02]\n",
      " [1.162e+01 1.990e+00 2.280e+00 ... 1.160e+00 2.960e+00 3.450e+02]\n",
      " ...\n",
      " [1.242e+01 1.610e+00 2.190e+00 ... 1.060e+00 2.960e+00 3.450e+02]\n",
      " [1.390e+01 1.680e+00 2.120e+00 ... 9.100e-01 3.330e+00 9.850e+02]\n",
      " [1.416e+01 2.510e+00 2.480e+00 ... 6.200e-01 1.710e+00 6.600e+02]]\n",
      "[3 2 2 3 1 1 2 2 2 1 3 2 3 1 3 3 1 3 1 2 3 3 2 3 3 1 2 3 2 2 3 2 1 2 2 2 1\n",
      " 1 2 2 3 3 2 2 2 3 3 1 3 2 2 2 2 2 1 1 2 1 3 1 3 1 1 2 1 2 2 1 3 2 1 2 2 2\n",
      " 3 1 3 3 1 1 2 3 1 1 2 2 1 1 1 3 2 1 2 3 1 2 3 3 1 1 3 1 3 2 1 1 2 1 3 2 3\n",
      " 1 3 3 3 1 2 2 2 2 3 3 2 2 1 2 3 3 1 1 3 2 2 2 1 1 1 2 2 2 1 3]\n",
      "[[1.374e+01 1.670e+00 2.250e+00 1.640e+01 1.180e+02 2.600e+00 2.900e+00\n",
      "  2.100e-01 1.620e+00 5.850e+00 9.200e-01 3.200e+00 1.060e+03]\n",
      " [1.279e+01 2.670e+00 2.480e+00 2.200e+01 1.120e+02 1.480e+00 1.360e+00\n",
      "  2.400e-01 1.260e+00 1.080e+01 4.800e-01 1.470e+00 4.800e+02]\n",
      " [1.237e+01 1.130e+00 2.160e+00 1.900e+01 8.700e+01 3.500e+00 3.100e+00\n",
      "  1.900e-01 1.870e+00 4.450e+00 1.220e+00 2.870e+00 4.200e+02]\n",
      " [1.356e+01 1.730e+00 2.460e+00 2.050e+01 1.160e+02 2.960e+00 2.780e+00\n",
      "  2.000e-01 2.450e+00 6.250e+00 9.800e-01 3.030e+00 1.120e+03]\n",
      " [1.305e+01 5.800e+00 2.130e+00 2.150e+01 8.600e+01 2.620e+00 2.650e+00\n",
      "  3.000e-01 2.010e+00 2.600e+00 7.300e-01 3.100e+00 3.800e+02]\n",
      " [1.156e+01 2.050e+00 3.230e+00 2.850e+01 1.190e+02 3.180e+00 5.080e+00\n",
      "  4.700e-01 1.870e+00 6.000e+00 9.300e-01 3.690e+00 4.650e+02]\n",
      " [1.406e+01 2.150e+00 2.610e+00 1.760e+01 1.210e+02 2.600e+00 2.510e+00\n",
      "  3.100e-01 1.250e+00 5.050e+00 1.060e+00 3.580e+00 1.295e+03]\n",
      " [1.236e+01 3.830e+00 2.380e+00 2.100e+01 8.800e+01 2.300e+00 9.200e-01\n",
      "  5.000e-01 1.040e+00 7.650e+00 5.600e-01 1.580e+00 5.200e+02]\n",
      " [1.225e+01 1.730e+00 2.120e+00 1.900e+01 8.000e+01 1.650e+00 2.030e+00\n",
      "  3.700e-01 1.630e+00 3.400e+00 1.000e+00 3.170e+00 5.100e+02]\n",
      " [1.208e+01 1.830e+00 2.320e+00 1.850e+01 8.100e+01 1.600e+00 1.500e+00\n",
      "  5.200e-01 1.640e+00 2.400e+00 1.080e+00 2.270e+00 4.800e+02]\n",
      " [1.336e+01 2.560e+00 2.350e+00 2.000e+01 8.900e+01 1.400e+00 5.000e-01\n",
      "  3.700e-01 6.400e-01 5.600e+00 7.000e-01 2.470e+00 7.800e+02]\n",
      " [1.388e+01 5.040e+00 2.230e+00 2.000e+01 8.000e+01 9.800e-01 3.400e-01\n",
      "  4.000e-01 6.800e-01 4.900e+00 5.800e-01 1.330e+00 4.150e+02]\n",
      " [1.420e+01 1.760e+00 2.450e+00 1.520e+01 1.120e+02 3.270e+00 3.390e+00\n",
      "  3.400e-01 1.970e+00 6.750e+00 1.050e+00 2.850e+00 1.450e+03]\n",
      " [1.237e+01 1.070e+00 2.100e+00 1.850e+01 8.800e+01 3.520e+00 3.750e+00\n",
      "  2.400e-01 1.950e+00 4.500e+00 1.040e+00 2.770e+00 6.600e+02]\n",
      " [1.358e+01 2.580e+00 2.690e+00 2.450e+01 1.050e+02 1.550e+00 8.400e-01\n",
      "  3.900e-01 1.540e+00 8.660e+00 7.400e-01 1.800e+00 7.500e+02]\n",
      " [1.200e+01 9.200e-01 2.000e+00 1.900e+01 8.600e+01 2.420e+00 2.260e+00\n",
      "  3.000e-01 1.430e+00 2.500e+00 1.380e+00 3.120e+00 2.780e+02]\n",
      " [1.376e+01 1.530e+00 2.700e+00 1.950e+01 1.320e+02 2.950e+00 2.740e+00\n",
      "  5.000e-01 1.350e+00 5.400e+00 1.250e+00 3.000e+00 1.235e+03]\n",
      " [1.419e+01 1.590e+00 2.480e+00 1.650e+01 1.080e+02 3.300e+00 3.930e+00\n",
      "  3.200e-01 1.860e+00 8.700e+00 1.230e+00 2.820e+00 1.680e+03]\n",
      " [1.264e+01 1.360e+00 2.020e+00 1.680e+01 1.000e+02 2.020e+00 1.410e+00\n",
      "  5.300e-01 6.200e-01 5.750e+00 9.800e-01 1.590e+00 4.500e+02]\n",
      " [1.383e+01 1.650e+00 2.600e+00 1.720e+01 9.400e+01 2.450e+00 2.990e+00\n",
      "  2.200e-01 2.290e+00 5.600e+00 1.240e+00 3.370e+00 1.265e+03]\n",
      " [1.311e+01 1.010e+00 1.700e+00 1.500e+01 7.800e+01 2.980e+00 3.180e+00\n",
      "  2.600e-01 2.280e+00 5.300e+00 1.120e+00 3.180e+00 5.020e+02]\n",
      " [1.305e+01 1.650e+00 2.550e+00 1.800e+01 9.800e+01 2.450e+00 2.430e+00\n",
      "  2.900e-01 1.440e+00 4.250e+00 1.120e+00 2.510e+00 1.105e+03]\n",
      " [1.324e+01 2.590e+00 2.870e+00 2.100e+01 1.180e+02 2.800e+00 2.690e+00\n",
      "  3.900e-01 1.820e+00 4.320e+00 1.040e+00 2.930e+00 7.350e+02]\n",
      " [1.251e+01 1.730e+00 1.980e+00 2.050e+01 8.500e+01 2.200e+00 1.920e+00\n",
      "  3.200e-01 1.480e+00 2.940e+00 1.040e+00 3.570e+00 6.720e+02]\n",
      " [1.233e+01 1.100e+00 2.280e+00 1.600e+01 1.010e+02 2.050e+00 1.090e+00\n",
      "  6.300e-01 4.100e-01 3.270e+00 1.250e+00 1.670e+00 6.800e+02]\n",
      " [1.252e+01 2.430e+00 2.170e+00 2.100e+01 8.800e+01 2.550e+00 2.270e+00\n",
      "  2.600e-01 1.220e+00 2.000e+00 9.000e-01 2.780e+00 3.250e+02]\n",
      " [1.243e+01 1.530e+00 2.290e+00 2.150e+01 8.600e+01 2.740e+00 3.150e+00\n",
      "  3.900e-01 1.770e+00 3.940e+00 6.900e-01 2.840e+00 3.520e+02]\n",
      " [1.216e+01 1.610e+00 2.310e+00 2.280e+01 9.000e+01 1.780e+00 1.690e+00\n",
      "  4.300e-01 1.560e+00 2.450e+00 1.330e+00 2.260e+00 4.950e+02]\n",
      " [1.176e+01 2.680e+00 2.920e+00 2.000e+01 1.030e+02 1.750e+00 2.030e+00\n",
      "  6.000e-01 1.050e+00 3.800e+00 1.230e+00 2.500e+00 6.070e+02]\n",
      " [1.378e+01 2.760e+00 2.300e+00 2.200e+01 9.000e+01 1.350e+00 6.800e-01\n",
      "  4.100e-01 1.030e+00 9.580e+00 7.000e-01 1.680e+00 6.150e+02]\n",
      " [1.339e+01 1.770e+00 2.620e+00 1.610e+01 9.300e+01 2.850e+00 2.940e+00\n",
      "  3.400e-01 1.450e+00 4.800e+00 9.200e-01 3.220e+00 1.195e+03]\n",
      " [1.422e+01 1.700e+00 2.300e+00 1.630e+01 1.180e+02 3.200e+00 3.000e+00\n",
      "  2.600e-01 2.030e+00 6.380e+00 9.400e-01 3.310e+00 9.700e+02]\n",
      " [1.204e+01 4.300e+00 2.380e+00 2.200e+01 8.000e+01 2.100e+00 1.750e+00\n",
      "  4.200e-01 1.350e+00 2.600e+00 7.900e-01 2.570e+00 5.800e+02]\n",
      " [1.421e+01 4.040e+00 2.440e+00 1.890e+01 1.110e+02 2.850e+00 2.650e+00\n",
      "  3.000e-01 1.250e+00 5.240e+00 8.700e-01 3.330e+00 1.080e+03]\n",
      " [1.483e+01 1.640e+00 2.170e+00 1.400e+01 9.700e+01 2.800e+00 2.980e+00\n",
      "  2.900e-01 1.980e+00 5.200e+00 1.080e+00 2.850e+00 1.045e+03]\n",
      " [1.305e+01 1.770e+00 2.100e+00 1.700e+01 1.070e+02 3.000e+00 3.000e+00\n",
      "  2.800e-01 2.030e+00 5.040e+00 8.800e-01 3.350e+00 8.850e+02]]\n",
      "[1 3 2 1 2 2 1 3 2 2 3 3 1 2 3 2 1 1 2 1 2 1 1 2 2 2 2 2 2 3 1 1 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# 3. VERÄ°LERÄ°N TEST VE TRAIN OLARAK BÃ–LÃœNMESÄ° [2.8]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.2,random_state=0)\n",
    "# Dataset 20% test ve 80%train olarak ikiye ile 13 X baÄŸÄ±msÄ±z ve 1 Y baÄŸÄ±mlÄ± deÄŸiÅŸken olarak 4 e ayrÄ±ldÄ±.\n",
    "\n",
    "print(x_train) # train 13 baÄŸÄ±msÄ±z deÄŸiÅŸkenler % 80 Dataset\n",
    "print(y_train) # train 1 baÄŸÄ±mlÄ± deÄŸiÅŸken      % 80 Dataset\n",
    "print(x_test)  # test 13 baÄŸÄ±msÄ±z deÄŸiÅŸken     % 20 Dataset\n",
    "print(y_test)  # train 1 baÄŸÄ±mlÄ± deÄŸiÅŸken      % 20 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. VERÄ°LERÄ°N Ã–ZNÄ°TELÄ°K SCALER Ã–LÃ‡EKLENMESÄ° [2.9] ANN-DEEP LEARNING Ä°Ã‡Ä°N DEÄžERLER 0-1 ARASI OLACAK\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(x_train) # X_train scale edilmiÅŸ baÄŸÄ±msÄ±z deÄŸiÅŸkenler train datalar \n",
    "X_test = sc.fit_transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21. PCA VE LDA Ä°LE BOYUT AZALTMA Ä°ÅžLEMLERÄ°:\n",
    "          \n",
    "# 21a.PCA MODEL OLUÅžTURMA VE BOYUT DÃ–NÃœÅžTÃœRME: \n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 2) # 2 boyutlu PCA obje urettik.\n",
    "\n",
    "# 21b.LDA MODEL OLUÅžTURMA VE BOYUT DÃ–NÃœÅžTÃœRME: \n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA(n_components = 2) # 2 boyutlu LDA obje urettik.\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "# 13 adet X BaÄŸÄ±msÄ±z X_train eÄŸitim ve X_test test deÄŸiÅŸkenlerine PCA uygulanmasÄ±\n",
    "# Burada Ã¶nemli olan pca objesinin fit edilmesi. Sadece train set ile eÄŸtiliyor. EÄŸitilen pca ile train ve test setler transform ediliyor.\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train) # Fit the model with X_train and apply the dimensionality reduction on X_train_pca.\n",
    "# Ã–lÃ§eklendirilmiÅŸ X_train eÄŸitim verisi (toplam verinin 80%) ile fit eÄŸitilip veri yeni hal alÄ±cak.\n",
    "# Bu sÃ¼reÃ§te 13 baÄŸÄ±msÄ±z deÄŸiÅŸken 2 boyuta dÃ¶nÃ¼ÅŸecek. KayÄ±palr olabilir.\n",
    "\n",
    "X_train_lda = lda.fit_transform(X_train,y_train) \n",
    "# DÄ°KKAT : neden scale edilmemiÅŸ y_trainde fit_transform ediliyor?.\n",
    "# LDA SUPERVÄ°SED gÃ¶zetimli yani etiketleri [y_train] baÄŸÄ±mlÄ± deÄŸiÅŸkenleride kullanacaktÄ±r. LDA-PCA arasÄ±ndaki TEK FARK BU.... \n",
    "# Etiketler sayesinde sÄ±nÄ±flar araÄ±ndaki farklarÄ± maksimize ediyor.\n",
    "\n",
    "X_test_pca = pca.transform(X_test) # Apply dimensionality reduction to X.\n",
    "# Ã–lÃ§eklendirilmiÅŸ X_test verisi; X_Train ile eÄŸitilen (fit edilen) pca objesi ile transform edilerek 13 (X) deÄŸiÅŸkenden 2 (X) DeÄŸiÅŸkene boyut azalttÄ±.\n",
    "# BURADA DÄ°KKAT TEST Ä°Ã‡Ä°N FIT YOK .. daha Ã¶nce it edilen X_train pca objesi ile eÄŸitilior. \n",
    "# TRAINDE FÄ°T EDÄ°LÄ°P EÄžÄ°TÄ°LEN MODEL TESTTE TRANSFORM EDÄ°LÄ°YOR. \n",
    "# TEKRAR TEST KUMESÄ° Ä°LE TRAIN YAPILMIYIR.\n",
    "\n",
    "X_test_lda = lda.transform(X_test) # lda objesi trainde fit edildiÄŸi iÃ§in sadece X_test verilerini yazÄ±yoruz.\n",
    "# Yani Ã¶lÃ§ekli X_train ve Ã¶lÃ§eksik y_train ile fit edilen lda objesi ile _test verileri transform ediliyor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 21a. SCALE - FIT VE TRANSFORM EDÄ°LEN VERÄ°LERÄ°N SINIFLANDIRILMASI (LOJÄ°STÄ°K REGRESYONLA YAPALIM) Ä°ÅžLEMLERÄ°: \n",
    "     # 5. LOJISTIK REGRESYON VE VÄ°ZUALÄ°ZATION [GÃ–RSELLEÅžTÄ°RME] :\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression # LR ile sÄ±nÄ±flandÄ±rma yapacaÄŸÄ±z.\n",
    "      \n",
    "    # PCA boyut azaltma yapÄ±lmadan yapÄ±lan SÄ±nÄ±flandÄ±rma iÅŸlemi:\n",
    "logr = LogisticRegression(random_state=0) # random state 0 ile aÅŸaÄŸÄ±daki ve bu sÄ±nÄ±flandÄ±rada aynÄ± algoritma kullanÄ±lacak.\n",
    "logr.fit(X_train,y_train) \n",
    "# Dikkat Boyut azaltma olmayan X_train ile fit edip eÄŸitim setindeki y deÄŸiÅŸkeni sÄ±nÄ±flandÄ±rÄ±lÄ±yor\n",
    "# SÄ±nÄ±flandÄ±rma yapÄ±lan set logr.fit objesinde,\n",
    "\n",
    "    # PCA boyut azaltma yapÄ±ldÄ±ktan sonra yapÄ±lan SÄ±nÄ±flandÄ±rma iÅŸlemi:\n",
    "logr_pca = LogisticRegression(random_state=0)\n",
    "logr_pca.fit(X_train_pca,y_train) # Dikkat Boyut azaltma yapÄ±lan X_train_pca ile fit edip eÄŸitim setindeki y deÄŸiÅŸkeni sÄ±nÄ±flandÄ±rÄ±lÄ±yor\n",
    "\n",
    "   # LDA boyut azaltma yapÄ±ldÄ±ktan sonra yapÄ±lan SÄ±nÄ±flandÄ±rma iÅŸlemi:\n",
    "logr_lda = LogisticRegression(random_state=0)\n",
    "logr_lda.fit(X_train_lda,y_train) # Ã–lÃ§eklenmiÅŸ ve 2 Boyuta LDA ile inmiÅŸ X_train eÄŸitim verilerinden y_train verilerini Ã¶ÄŸrenecek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11.e PREDICT TAHMÄ°N ETMEK :\n",
    "'''\n",
    "Model.predict(\n",
    "    x,\n",
    "    batch_size=None,\n",
    "    verbose=0,\n",
    "    steps=None,\n",
    "    callbacks=None,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False,\n",
    ")\n",
    "'''\n",
    "y_pred = logr.predict(X_test) \n",
    "# PSA YAPILMADAN 13 BAÄžIMSIZ DEÄžÄ°ÅžKEN (X_test) Ä°LE YAPILAN BAÄžIMLI DEÄžÄ°ÅžKEN TAHMÄ°NÄ° \n",
    "y_pred_psa = logr_pca.predict(X_test_pca) \n",
    "# PSA YAPILDIKTAN SONRA 2 BAÄžIMSIZ DEÄžÄ°ÅžKEN (X_test_psa) Ä°LE YAPILAN BAÄžIMLI DEÄžÄ°KEN TAHMÄ°NÄ° \n",
    "y_pred_lda = logr_lda.predict(X_test_lda) \n",
    "# LDA YAPILDIKTAN SONRA 2 BAÄžIMSIZ DEÄžÄ°ÅžKEN (X_test_lda) Ä°LE YAPILAN BAÄžIMLI DEÄžÄ°KEN TAHMÄ°NÄ° "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Y_test (GERÃ‡EK SONUÃ‡) Ä°LE Y_Pred (PSA olmadan tahmin KarÅŸÄ±laÅŸtÄ±rmasÄ±) :\n",
      "[[14  0  0]\n",
      " [ 0 15  1]\n",
      " [ 0  0  6]]\n",
      " Y_test (GERÃ‡EK SONUÃ‡) Ä°LE Y_Pred_psa (PSA yapÄ±larak tahmin KarÅŸÄ±laÅŸtÄ±rmasÄ±) :\n",
      "[[14  0  0]\n",
      " [ 1 15  0]\n",
      " [ 0  0  6]]\n",
      " Y_Pred (Tahmni SonuÃ§) Ä°LE Y_Pred_psa (PSA yapÄ±larak tahmin KarÅŸÄ±laÅŸtÄ±rmasÄ±) :\n",
      "[[14  0  0]\n",
      " [ 1 14  0]\n",
      " [ 0  1  6]]\n",
      " Y_test (GERÃ‡EK SONUÃ‡) Ä°LE Y_Pred_lda (LDA yapÄ±larak tahmin KarÅŸÄ±laÅŸtÄ±rmasÄ±) :\n",
      "[[14  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  0  6]]\n"
     ]
    }
   ],
   "source": [
    "# 12. KARÅžILAÅžTIRMA MATRIXI\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\" Y_test (GERÃ‡EK SONUÃ‡) Ä°LE Y_Pred (PSA olmadan tahmin KarÅŸÄ±laÅŸtÄ±rmasÄ±) :\")\n",
    "cm_1 = confusion_matrix(y_test,y_pred)\n",
    "print(cm_1)\n",
    "\n",
    "\n",
    "print(\" Y_test (GERÃ‡EK SONUÃ‡) Ä°LE Y_Pred_psa (PSA yapÄ±larak tahmin KarÅŸÄ±laÅŸtÄ±rmasÄ±) :\")\n",
    "cm_2 = confusion_matrix(y_test,y_pred_psa)\n",
    "print(cm_2)\n",
    "\n",
    "print(\" Y_Pred (Tahmni SonuÃ§) Ä°LE Y_Pred_psa (PSA yapÄ±larak tahmin KarÅŸÄ±laÅŸtÄ±rmasÄ±) :\")\n",
    "cm_3 = confusion_matrix(y_pred,y_pred_psa)\n",
    "print(cm_3)\n",
    "\n",
    "print(\" Y_test (GERÃ‡EK SONUÃ‡) Ä°LE Y_Pred_lda (LDA yapÄ±larak tahmin KarÅŸÄ±laÅŸtÄ±rmasÄ±) :\")\n",
    "cm_4 = confusion_matrix(y_test,y_pred_lda)\n",
    "print(cm_4) # LDA - GerÃ§ek sonuÃ§ mukemmel Ã§Ä±ktÄ± % 100 baÅŸarÄ±lÄ± oldu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. CONFUSION MATRIX (KARMAÅžIKLIK MATRISI) :\n",
    "\n",
    "#  G                TAHMÄ°N PREDICTION\n",
    "#  E -----------------------------------------------\n",
    "#  R   True-Positive  (TP)   +   False-Negative (FN)\n",
    "#  Ã‡   +++++++++++++++++++++++++++++++++++++++++++++\n",
    "#  E   False-Positive (FP)   +   True-Negative  (TN)\n",
    "#  K\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred) # y_test gerÃ§ek ve y_pred tahmini cinsiyet karÅŸÄ±laÅŸtrmasÄ±\n",
    "\n",
    "# Matris deÄŸerlerinin incelenmesi:\n",
    "SatÄ±r0 = cm[0] # TP+FN\n",
    "TP = SatÄ±r0[0]\n",
    "FN = SatÄ±r0[1]\n",
    "SatÄ±r1 = cm[1] # FP+TN\n",
    "FP = SatÄ±r1[0]\n",
    "TN = SatÄ±r1[1]\n",
    "\n",
    "\n",
    "print(cm)\n",
    "print (y_test,y_pred) # HiÃ§biri tutmamÄ±ÅŸ ..ðŸ˜ŽðŸ˜¯\n",
    "\n",
    "print(\"Accuracy Rate    [DoÄŸruluk OranÄ±]= \",\"%\", ((TP+TN)/(TP+FN+FP+TN))*100)\n",
    "print(\"Error Rate       [Hata OranÄ±]=     \",\"%\", ((100-((TP+TN)/(TP+FN+FP+TN))*100)))\n",
    "print(\"Precision Rate   [Kesinlik OranÄ±]= \",\"%\", ((TP)/(TP+FP))*100)\n",
    "print(\"Specificity-True/Neg rate (TNR)=   \",\"%\", ((TN/(FP+TN))*100))\n",
    "print(\"Sensitivity-Recall Rate -True/Pos Rate [Hassasiyet OranÄ±]=\",\"%\",((TP)/(TP+FN))*100)\n",
    "# Burada en Ã¶nemli nokta tahmin edilen baÄŸÄ±mlÄ± deÄŸiÅŸkeninin balanced olmasÄ± gerkiyor. Yani %90 Erkek ve\n",
    "# 10% kadÄ±n olan veri setinde Accuracy Rate in 90% olmasÄ± baÅŸarÄ± deÄŸildir. KadÄ±nÄ± bulamama ihtimallerine\n",
    "# raÄŸmen 90% erkek bulacaÄŸÄ± iÃ§in Accuracy Rate hata yaptÄ±rÄ±r. Bundan dolayÄ± diÄŸer deÄŸerlerede bakÄ±lmalÄ±dÄ±r."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
